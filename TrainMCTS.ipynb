{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yUTHtF9bV6A",
        "outputId": "05cf7c3c-5571-4a29-edee-d3d874c52a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd drive/MyDrive/chess_ai_colab"
      ],
      "metadata": {
        "id": "4DO9tqUccf2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q5jJDb_5eLfF",
        "outputId": "564fb259-7bd9-4944-b999-aa240504dde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTfMcjKifGUC",
        "outputId": "94a4caab-3dd1-4142-e625-fc3136a19890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chess\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=0f91b5f2b5bb706ca6d6684d45414144f369c6c00c2b7c8cce68eceba49648d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: chess\n",
            "Successfully installed chess-1.11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import chess\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "Inns3iIHeOLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = \"/content/drive/MyDrive/chess_ai_colab/data/lichess_db_standard_rated_2015-08.pgn.zst\"\n",
        "OUTPUT_PGN = \"/content/drive/MyDrive/chess_ai_colab/data/lichess_db_standard_rated_2015-08.pgn\"\n",
        "\n",
        " #Giải nén .zst → .pgn\n",
        "import zstandard as zstd\n",
        "import shutil\n",
        "\n",
        "with open(INPUT_PATH, 'rb') as compressed:\n",
        "    dctx = zstd.ZstdDecompressor()\n",
        "    with dctx.stream_reader(compressed) as reader, open(OUTPUT_PGN, 'wb') as out:\n",
        "        shutil.copyfileobj(reader, out)\n",
        "print(\"Giải nén xong:\", OUTPUT_PGN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WisKT1neP5L",
        "outputId": "709e2bb8-a911-481f-afb6-f14bf31d7d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Giải nén xong: /content/drive/MyDrive/chess_ai_colab/data/lichess_db_standard_rated_2015-08.pgn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm chuyển Board → tensor (12×8×8) và move → index (64×64 = 4096)\n",
        "import chess\n",
        "import numpy as np\n",
        "\n",
        "def board_to_tensor(board: chess.Board):\n",
        "    planes = np.zeros((12, 8, 8), dtype=np.float32)\n",
        "    for square, piece in board.piece_map().items():\n",
        "        idx = (piece.piece_type - 1) + (0 if piece.color == chess.WHITE else 6)\n",
        "        rank = chess.square_rank(square)\n",
        "        file = chess.square_file(square)\n",
        "        planes[idx][7 - rank][file] = 1.0\n",
        "    return planes\n",
        "\n",
        "def move_to_index(move: chess.Move):\n",
        "    return move.from_square * 64 + move.to_square"
      ],
      "metadata": {
        "id": "9sRnPKHtfRir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm chuyển Board → tensor (12×8×8) và move → index (64×64 = 4096)\n",
        "import chess\n",
        "import numpy as np\n",
        "\n",
        "def board_to_tensor(board: chess.Board):\n",
        "    planes = np.zeros((12, 8, 8), dtype=np.float32)\n",
        "    for square, piece in board.piece_map().items():\n",
        "        idx = (piece.piece_type - 1) + (0 if piece.color == chess.WHITE else 6)\n",
        "        rank = chess.square_rank(square)\n",
        "        file = chess.square_file(square)\n",
        "        planes[idx][7 - rank][file] = 1.0\n",
        "    return planes\n",
        "\n",
        "def move_to_index(move: chess.Move):\n",
        "    return move.from_square * 64 + move.to_square\n",
        "\n",
        "# Đọc PGN và tạo dataset supervised\n",
        "import chess.pgn\n",
        "\n",
        "MAX_GAMES = 5000          # có thể tăng lên 20000–50000 tuỳ tài nguyên\n",
        "MAX_MOVES_PER_GAME = 40   # chỉ lấy tối đa 40 nước đầu mỗi ván\n",
        "\n",
        "states = []\n",
        "policies = []\n",
        "\n",
        "with open(OUTPUT_PGN, 'r', errors='ignore') as pgn_file:\n",
        "    game_count = 0\n",
        "    while game_count < MAX_GAMES:\n",
        "        game = chess.pgn.read_game(pgn_file)\n",
        "        if game is None:\n",
        "            break\n",
        "        game_count += 1\n",
        "        board = game.board()\n",
        "        move_count = 0\n",
        "        for node in game.mainline():\n",
        "            move = node.move\n",
        "            if move is None:\n",
        "                continue\n",
        "            state_tensor = board_to_tensor(board)\n",
        "            idx = move_to_index(move)\n",
        "            policy_vec = np.zeros(4096, dtype=np.float32)\n",
        "            policy_vec[idx] = 1.0\n",
        "            states.append(state_tensor)\n",
        "            policies.append(policy_vec)\n",
        "            board.push(move)\n",
        "            move_count += 1\n",
        "            if move_count >= MAX_MOVES_PER_GAME:\n",
        "                break\n",
        "        if game_count % 500 == 0:\n",
        "            print(f\"Đã xử lý {game_count} ván...\")\n",
        "\n",
        "states_arr = np.array(states, dtype=np.float32)      # (N,12,8,8)\n",
        "policies_arr = np.array(policies, dtype=np.float32)  # (N,4096)\n",
        "DATASET_PATH = \"/content/drive/MyDrive/chess_ai_colab/data/lichess_dataset.npz\"\n",
        "np.savez(DATASET_PATH, states=states_arr, policies=policies_arr)\n",
        "print(\"Lưu dataset xong:\", DATASET_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_0etpJ8fa7x",
        "outputId": "3b69c3a4-489e-4066-92ae-2c414056fcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đã xử lý 500 ván...\n",
            "Đã xử lý 1000 ván...\n",
            "Đã xử lý 1500 ván...\n",
            "Đã xử lý 2000 ván...\n",
            "Đã xử lý 2500 ván...\n",
            "Đã xử lý 3000 ván...\n",
            "Đã xử lý 3500 ván...\n",
            "Đã xử lý 4000 ván...\n",
            "Đã xử lý 4500 ván...\n",
            "Đã xử lý 5000 ván...\n",
            "Lưu dataset xong: /content/drive/MyDrive/chess_ai_colab/data/lichess_dataset.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResidualBlock (giữ nguyên, nhận param channels)\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out)) + residual\n",
        "        out = F.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "FEO4-fLAfkQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PolicyNet dày hơn: 20 ResNet blocks, num_channels=256\n",
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self, num_res_blocks=20, num_channels=256, action_size=4096):\n",
        "        \"\"\"\n",
        "        - num_res_blocks: 20 (tăng rất sâu)\n",
        "        - num_channels: 256 (tăng kênh)\n",
        "        - action_size: 4096 (64×64 mapping)\n",
        "        \"\"\"\n",
        "        super(PolicyNet, self).__init__()\n",
        "        # Layer đầu vào: từ 12 plane → num_channels\n",
        "        self.conv_in = nn.Conv2d(12, num_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn_in = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "        # Tạo 20 Residual Blocks\n",
        "        self.res_blocks = nn.ModuleList([ResidualBlock(num_channels) for _ in range(num_res_blocks)])\n",
        "\n",
        "        # Policy head: 1×1 conv giảm channels xuống 32, rồi FC → action_size\n",
        "        self.conv_policy = nn.Conv2d(num_channels, 32, kernel_size=1)\n",
        "        self.bn_policy = nn.BatchNorm2d(32)\n",
        "        self.fc_policy = nn.Linear(32 * 8 * 8, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, 12, 8, 8)\n",
        "        out = F.relu(self.bn_in(self.conv_in(x)))\n",
        "        for block in self.res_blocks:\n",
        "            out = block(out)\n",
        "        p = F.relu(self.bn_policy(self.conv_policy(out)))  # (batch, 32, 8, 8)\n",
        "        p = p.view(p.size(0), -1)                           # (batch, 32*8*8)\n",
        "        p = self.fc_policy(p)                               # (batch, action_size)\n",
        "        return p"
      ],
      "metadata": {
        "id": "H3vPWw21flu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset từ file .npz\n",
        "data = np.load(DATASET_PATH)\n",
        "states = data[\"states\"]      # (N,12,8,8)\n",
        "policies = data[\"policies\"]  # (N,4096)\n",
        "\n",
        "# Dataset class\n",
        "class LichessDataset(Dataset):\n",
        "    def __init__(self, states, policies):\n",
        "        self.states = torch.from_numpy(states)       # (N,12,8,8)\n",
        "        self.policies = torch.from_numpy(policies)   # (N,4096)\n",
        "    def __len__(self):\n",
        "        return self.states.size(0)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.states[idx], self.policies[idx]\n",
        "\n",
        "dataset = LichessDataset(states, policies)\n",
        "\n",
        "# DataLoader với batch_size lớn hơn (ví dụ 128)\n",
        "batch_size = 128\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "print(\"Dataset size:\", len(dataset), \"Batch size:\", batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiVOpd-afzUB",
        "outputId": "67ffe18a-5d49-4506-b664-ce233fbb50eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 188098 Batch size: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo model, optimizer, criterion\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PolicyNet(num_res_blocks=20, num_channels=256, action_size=4096).to(device)\n",
        "\n",
        "learning_rate = 0.0005  # giảm so với 0.001 ban đầu\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "start_epoch = 0\n",
        "\n",
        "# Resume\n",
        "# checkpoint = torch.load(\"/content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_5.pt\", map_location=device)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# start_epoch = checkpoint['epoch']\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_states, batch_policies in dataloader:\n",
        "        batch_states = batch_states.to(device)  # (B,12,8,8)\n",
        "        idxs = torch.argmax(batch_policies, dim=1).to(device)  # (B,)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_states)  # (B,4096)\n",
        "        loss = criterion(logits, idxs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 5.3. Lưu checkpoint mỗi 5 epoch\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_path = f\"/content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_{epoch+1}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_loss\n",
        "        }, ckpt_path)\n",
        "        print(\"Saved checkpoint:\", ckpt_path)\n",
        "\n",
        "# 5.4. Lưu model cuối cùng\n",
        "MODEL_PATH = \"/content/drive/MyDrive/chess_ai_colab/models/policy_supervised_final.pt\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Đã lưu model cuối:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx_92OGmgATK",
        "outputId": "89bb7745-be18-4898-80f1-8c4c84d0c64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 4.2104\n",
            "Epoch [2/20], Loss: 3.0144\n",
            "Epoch [3/20], Loss: 2.6079\n",
            "Epoch [4/20], Loss: 2.3452\n",
            "Epoch [5/20], Loss: 2.1418\n",
            "Saved checkpoint: /content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_5.pt\n",
            "Epoch [6/20], Loss: 1.9637\n",
            "Epoch [7/20], Loss: 1.8119\n",
            "Epoch [8/20], Loss: 1.6801\n",
            "Epoch [9/20], Loss: 1.5595\n",
            "Epoch [10/20], Loss: 1.4565\n",
            "Saved checkpoint: /content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_10.pt\n",
            "Epoch [11/20], Loss: 1.3604\n",
            "Epoch [12/20], Loss: 1.2767\n",
            "Epoch [13/20], Loss: 1.1978\n",
            "Epoch [14/20], Loss: 1.1347\n",
            "Epoch [15/20], Loss: 1.0695\n",
            "Saved checkpoint: /content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_15.pt\n",
            "Epoch [16/20], Loss: 1.0203\n",
            "Epoch [17/20], Loss: 0.9738\n",
            "Epoch [18/20], Loss: 0.9270\n",
            "Epoch [19/20], Loss: 0.8896\n",
            "Epoch [20/20], Loss: 0.8591\n",
            "Saved checkpoint: /content/drive/MyDrive/chess_ai_colab/checkpoints/ckpt_epoch_20.pt\n",
            "Đã lưu model cuối: /content/drive/MyDrive/chess_ai_colab/models/policy_supervised_final.pt\n"
          ]
        }
      ]
    }
  ]
}